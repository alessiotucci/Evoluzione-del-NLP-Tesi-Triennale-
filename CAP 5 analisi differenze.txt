who is watching johnny depp vs amber heard defamation trial yesterday in the trial ron chanel the director at berkeley research group testified about the negative hashtags and tweets towards amber heard so that makes me wonder why did i just try to do some simple text analysis on tweets that mentioned johnny depp and never heard and see what the data shows i plan to get two days of twitter data mentioning johnny depp amber heard camilla vasquez and shannon curry show a live coding on how i actually clean and work with the data apply a pre-trained hugging phase sentiment model for sentiment analysis and then finally show some in-gram analysis as well as topic modeling okay so let's get started let's first create a new content environment we call it twitter analysis i always create a new content environment for my new projects and then we can kind of activate this environment and then install the packages we need i'm installing pandas numpy pytorch psychic learn nltk hp plot transformers notebook and pip and then i'm going to pipping stall sns grape i'm gonna show you in a little bit why i need to install this and then i launch a jupyter notebook so i did some research previously on how to get data from twitter so here's one of the article that i like this article uses sns script and i'm just gonna copy and paste some code directly from this article there's another tool called tweepy or tree pie um but that tool has limitations and needs to use developer apis so i thought this is better so i think i'm gonna create a function first so that i can get different tweets for different person using just a function and i'm gonna return the data frame in the function i'm gonna set some parameters i think i'm gonna set the number of tweets first i'm gonna call it end tweets and then i'm gonna delete the username because i don't think i need to use the twitter username and then i want to use a parameter search term as a parameter in the function and also the start date and end date i'm just gonna organize it into another cell okay i'm missing a column here i'm gonna give this function some descriptions get a data frame of tweets by search term and i want to link the reference in my code so that people know i borrowed the code from somewhere else and then let's just test it i'm going to test this function with the search term happy with end tweets equals 10 and my start date is may 8 may 19 and my start date is may 19 and my end date is may 20th and it looks pretty good it actually returned 11 tweets which means the number of tweets returned is actually untwist plus one which is okay now we can get actual tweets for our analysis in addition to getting the tweets with the search term johnny depp and amber heard i i'm also interested in the tweets i'm mentioning camilla vasquez and shannon curry since they are the superstars in the trial so i thought i would like to get tweets mentioning them as well i'm getting i'm trying to get tweets for the past two days and with the limit of ten thousand and one tweet am i i'm changing the search terms to each person's name and for shannon curry i am actually going to change the day to be a little longer since there are not many tweets mentioning shannon curry for in the past two days now i'm trying to see the length of the data frames here is what the data looks like we have the date time we have the twitter id and the text of the tweet since we have four data frames i think it will be smart to start with just one data frame to take a look at how we should process the data i'm just going to use the data frame dm df so that i don't need to write so many words for my data processing steps now i'm i am investigating one of the tweet so let's think about it what kind of data cleaning steps that we need for this tweet the first thing is to make everything lowercase the second is that we should remove the rows that are mentioning the other three people probably so that the sentiment we know is more precisely towards this person we're looking at and also we want to keep the roles dimensioning the person of interest and then finally i think we should remove all the urls because those are irrelevant for our text analysis okay now we can work on each individual data cleaning steps first we want to make everything lowercase let's write df equals df dot assign i'm trying to use the assign function here to create a new column text to override the existing column text with everything lowercase i use the assign method here because i want to use pandas method chaining later and when we check the first record it looks pretty good the second step is to remove the rows that i'm mentioning all the other three people so here we can use dot query method and filter out the text with a string that contains either the first name or the other or the either the first name or the last name of other three people i separated the names by a vertical bar and then we can do some quick checks to see if we get everything right okay i'm just going to try to check some individual sales and then i want to check if any of the rows mentioning johnny depp okay everything looks good similarly i want to keep the rose dimensioning come in the baskets again we use string contains and camilla vertical bar baskets the final data cleaning step is to remove all the urls i actually don't know how to do that so i'm just gonna google it just gonna google remove http urls from string in python okay i'm just going to copy and paste one of the answers here since we're using python 3 we need to use parenthesis with print okay and i want to get a real tweet example to see if a tweet works here string contains okay i want to get a 37 okay that's not going to work right we need to specify the column text okay it looks like this function actually works okay i want to move the import up front so it's more organized now we can do another df.assign to create this new text column to overwrite the existing text column with all the urls removed okay there is no rows containing https so that is great next step we could do some sentiment analysis i'm thinking to use some hugging face pre-trained models so again i'm gonna do some googling on how to do that because i don't remember all the sync text okay let's copy and paste the models now looking at the document i noticed there is a freight train model trained um twitter data so i think we should probably use this model instead so i'm going to change the model to this twitter model this model is actually trained on about 58 million tweets so that'll be great for our analysis we want to use the right index okay looks like it's labeling our example tweet as label 2 which is positive that sounds about right again we would like to move all the imports into the beginning of the file to keep things organized and we would like to apply this sentiment model to every tweet in the data frame and we save the results in this new column called sentiment okay this this is the data looks like now we have a new column called sentiment notice that each sentiment result has a label and a score we would like to get them out as individual columns so first we should get the sentiment label out again we create a new column called cinnamon label which is a lambda function working on the sentiment column and extract the label out of the cell and similarly we can extract the cinnamon score using the same syntax okay now in the data frame we have sentiment label and then sentiment score we should probably also recode the cinnamon labels into negative and positive and neutral so here i used a numpy dot where function want the format to look a little better so the logic is if the sentiment label equals label underscore 0 then the label should be negative and if the cinnamon label is labeled underscore two it is positive otherwise it should be neutral okay just checking the data briefly it looks pretty good now we can do the same data processing steps for all of the four data frames briefly take a look at each of the data frame we have the data frame for camilla and for johnny depp hamper and then you have shannon okay they all look the same let's organize them into a df underscore dict it's a dictionary with the keys as the names of the person and the value is their corresponding data frames so amber heard and then colin do you have amber and then shannon curry df shannon okay now we can organize our data cleaning steps i'm just copying paste all the steps that we have done before and i like to use pandas method chaining to chain all the functions together this way it looks a little more organized missing a parenthesis here okay good now i have the assign dot query dot query and then dot sign okay those are the four data cleaning steps we have down above and the names of the other three people would be different for different data set so we would like to organize those into a dictionary as well with the keys again as a person's name and the value as the the string we want to remove or the rows containing the string we want to remove okay for johnny would have amber and camilla baskets and then for amber let's copy and paste and then when you add add johnny depp and then finally for shiner shannon we have amber heard okay looks good so far and then similarly we can use f string for the rows that mentioning individual names let's create a new dictionary called keep rows and we would like to keep the rows that containing each person's first name or last name so he should be amber heard for amber heard and then shannon curry for shannon curry okay now since we have four data frames we want to write a for loop this is a dictionary we can do for key and uh df in do you have underscore dict items and then we can loop through each of the dictionary and change the value of df underscore key which is the dictionary which is the data frame for each person and we also would like to print how many rows for each data frame now we have okay we still have a good amount of tweets to work with and then we can do sentiment analysis for all of the four data frames again we want to copy and paste some of the code that we did before again i would like to use panda's method chaining to chain all the method together we have df the assign dot assign and another dot assign so we created three new columns in this steps apply the pre-trained sentiment model and then we would like to write a for loop to loop all the data together so we can apply the sentiment analysis for all four data frames we would like to change the data frames in the data dictionary so so that we can call them out later and then there's one more step to recode the sentiment labels okay so that's the sentiment analysis in a for loop i'm fast forwarding the step because it's taking a while to run okay now we can check data frames for each person we can see for johnny depp sentiment label we can count how many labels are neutral how many are negative and how many are positive we probably want to only keep the cement label for those with high cinnamon scores so i'm gonna have a filter to audi keep cinnamon score greater than 0.8 i think that will give us a more a little more accurate result and then for amber heard the positive tweets or the numbers of positive tweets are really low for him or heard and then we want to um combine all those into one data frame so now we can do a plot in a little bit okay i guess x s equals one maybe okay that works now we can add the other two data frames let's just copy and paste and then we can change the names we have camilla baskets and uh shannon curry okay perfect this is the count data so i give it a name dfc and i would like to rename the columns so we have emperor heard capitalize the names come in the cap baskets okay now the data looks better now i like to calculate the percentage for each person because the total number of tweets varies dramatically for them so percentage makes more sense so i'm calling this percentage table dfp and then import hp plot.pandas i'm going to use hp plot to plot this data frame again we want to move the import to the beginning of the file oh actually i imported numpy earlier um we need numpy for for this analysis yeah dfp.hbplot.bar and this will give you a bar plot and you want to transpose this data and then wrote equals 90 which means the rotation of of the labels is 90 degrees you know when you change the color okay now we can compare the table with the um with the plot we just created you can see the number matches with the table so everything looks correct to me so looks like there are more negative tweets mentioning ever heard and there are more positive tweets mentioning camilla baskets okay now i would like to try some other analysis i wrote this text analysis blog post earlier i'm just going to copy and paste some code and we're going to do some engram analysis and then some topic modeling so first with the engram analysis i'm going to copy the nltk code we want a list of stop words and then okay yeah it should be text not reviews that's the name of the column we're interested in right we want to look at the communal baskets data camera okay we can see the top 10 uh engrams for tweets mentioning kamina baskets they'll look positive like positive tweets okay now we can try some topic modeling again just copy and paste code from my blog post and change the reviews to text and i want to change the number of topics to five maybe and showing me five words for each topic so the five topics looks like the first one topic zero is people who have a crush on criminal baskets topic one is people love camilla baskets topic two is coming on baskets queen three is want i'm gonna baskets four is kim damascus tweet so all seem very positive to me from our simple analysis of two days of tweets it looks like camilla vazquez might be the actual winner of this trial people really love her keep in mind that this is just a toy example there are a lot of limitations to this analysis for example the data is not adequate or well sampled for any conclusions second the pre-trained model does get a lot of the sentiment wrong for example it thinks badass is a negative sentiment i don't have time to train the model further but if anyone has time it'll be interesting to label some tweets mentioning johnny depp and emma heard and entering the model further based on the pre-trained model it would also be super interesting to see how the sentiment for each person changed over time in the past month that's it for today's video thank you so much for watching bye